"""
ë°ì´í„° ì •í•©ì„± ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•˜ê³  ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- ì¤‘ë³µ ë°ì´í„° ì²´í¬
- NULL ê°’ í†µê³„
- ë‚ ì§œ ì—°ì†ì„± í™•ì¸
- ê°€ê²© ì´ìƒì¹˜ íƒì§€
- ì¢…ëª©ë³„ ìˆ˜ì§‘ í˜„í™©
"""

import sqlite3
import logging
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any
from collections import defaultdict
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.database import get_db_connection
from app.config import Config

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataQualityValidator:
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í´ë˜ìŠ¤"""

    def __init__(self):
        self.conn = get_db_connection()
        self.issues = defaultdict(list)
        self.stats = {}

    def check_duplicate_prices(self) -> Dict[str, int]:
        """
        ê°€ê²© ë°ì´í„° ì¤‘ë³µ ì²´í¬

        Returns:
            ì¢…ëª©ë³„ ì¤‘ë³µ ê±´ìˆ˜
        """
        logger.info("ê°€ê²© ë°ì´í„° ì¤‘ë³µ ì²´í¬ ì‹œì‘...")

        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT ticker, date, COUNT(*) as count
            FROM prices
            GROUP BY ticker, date
            HAVING count > 1
        """)

        duplicates = {}
        for row in cursor.fetchall():
            ticker = row['ticker']
            duplicates[ticker] = duplicates.get(ticker, 0) + row['count'] - 1
            self.issues['duplicates'].append({
                'table': 'prices',
                'ticker': ticker,
                'date': row['date'],
                'count': row['count']
            })

        logger.info(f"ì¤‘ë³µ ë°ì´í„°: {len(self.issues['duplicates'])}ê±´")
        return duplicates

    def check_null_values(self) -> Dict[str, Dict[str, int]]:
        """
        NULL ê°’ í†µê³„

        Returns:
            í…Œì´ë¸”ë³„, ì»¬ëŸ¼ë³„ NULL ê±´ìˆ˜
        """
        logger.info("NULL ê°’ í†µê³„ ìˆ˜ì§‘ ì‹œì‘...")

        null_stats = {}
        cursor = self.conn.cursor()

        # prices í…Œì´ë¸” NULL ì²´í¬
        cursor.execute("""
            SELECT
                COUNT(*) as total,
                SUM(CASE WHEN open_price IS NULL THEN 1 ELSE 0 END) as null_open,
                SUM(CASE WHEN high_price IS NULL THEN 1 ELSE 0 END) as null_high,
                SUM(CASE WHEN low_price IS NULL THEN 1 ELSE 0 END) as null_low,
                SUM(CASE WHEN close_price IS NULL THEN 1 ELSE 0 END) as null_close,
                SUM(CASE WHEN volume IS NULL THEN 1 ELSE 0 END) as null_volume,
                SUM(CASE WHEN daily_change_pct IS NULL THEN 1 ELSE 0 END) as null_change_pct
            FROM prices
        """)

        row = cursor.fetchone()
        total = row['total']

        if total > 0:
            null_stats['prices'] = {
                'total_records': total,
                'open_price': row['null_open'],
                'high_price': row['null_high'],
                'low_price': row['null_low'],
                'close_price': row['null_close'],
                'volume': row['null_volume'],
                'daily_change_pct': row['null_change_pct']
            }

            for col, count in null_stats['prices'].items():
                if col != 'total_records' and count > 0:
                    self.issues['null_values'].append({
                        'table': 'prices',
                        'column': col,
                        'count': count,
                        'percentage': round(count / total * 100, 2)
                    })

        # trading_flow í…Œì´ë¸” NULL ì²´í¬
        cursor.execute("""
            SELECT
                COUNT(*) as total,
                SUM(CASE WHEN individual_net IS NULL THEN 1 ELSE 0 END) as null_individual,
                SUM(CASE WHEN institutional_net IS NULL THEN 1 ELSE 0 END) as null_institutional,
                SUM(CASE WHEN foreign_net IS NULL THEN 1 ELSE 0 END) as null_foreign
            FROM trading_flow
        """)

        row = cursor.fetchone()
        total = row['total']

        if total > 0:
            null_stats['trading_flow'] = {
                'total_records': total,
                'individual_net': row['null_individual'],
                'institutional_net': row['null_institutional'],
                'foreign_net': row['null_foreign']
            }

        logger.info(f"NULL ê°’ ì´ìŠˆ: {len(self.issues['null_values'])}ê±´")
        return null_stats

    def check_date_continuity(self) -> Dict[str, List[str]]:
        """
        ë‚ ì§œ ì—°ì†ì„± í™•ì¸ (ì£¼ë§ ì œì™¸)

        Returns:
            ì¢…ëª©ë³„ ëˆ„ë½ëœ ë‚ ì§œ ëª©ë¡
        """
        logger.info("ë‚ ì§œ ì—°ì†ì„± í™•ì¸ ì‹œì‘...")

        missing_dates = {}
        cursor = self.conn.cursor()

        # ê° ì¢…ëª©ë³„ë¡œ ë‚ ì§œ ì—°ì†ì„± í™•ì¸
        stock_config = Config.get_stock_config()

        for ticker in stock_config.keys():
            cursor.execute("""
                SELECT date
                FROM prices
                WHERE ticker = ?
                ORDER BY date
            """, (ticker,))

            dates = [datetime.strptime(row['date'], '%Y-%m-%d').date()
                    for row in cursor.fetchall()]

            if len(dates) < 2:
                continue

            # ì²« ë‚ ì§œë¶€í„° ë§ˆì§€ë§‰ ë‚ ì§œê¹Œì§€ì˜ ëª¨ë“  í‰ì¼ ê³„ì‚°
            start_date = dates[0]
            end_date = dates[-1]

            expected_dates = []
            current = start_date
            while current <= end_date:
                # ì£¼ë§(í† ìš”ì¼=5, ì¼ìš”ì¼=6) ì œì™¸
                if current.weekday() < 5:
                    expected_dates.append(current)
                current += timedelta(days=1)

            # ì‹¤ì œ ë‚ ì§œì™€ ë¹„êµ
            actual_dates_set = set(dates)
            missing = [d for d in expected_dates if d not in actual_dates_set]

            if missing:
                missing_dates[ticker] = [d.strftime('%Y-%m-%d') for d in missing]
                self.issues['missing_dates'].append({
                    'ticker': ticker,
                    'count': len(missing),
                    'dates': missing_dates[ticker][:5]  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                })

        logger.info(f"ë‚ ì§œ ëˆ„ë½ ì´ìŠˆ: {len(self.issues['missing_dates'])}ê°œ ì¢…ëª©")
        return missing_dates

    def check_price_anomalies(self) -> Dict[str, List[Dict]]:
        """
        ê°€ê²© ì´ìƒì¹˜ íƒì§€

        Returns:
            ì¢…ëª©ë³„ ì´ìƒì¹˜ ëª©ë¡
        """
        logger.info("ê°€ê²© ì´ìƒì¹˜ íƒì§€ ì‹œì‘...")

        anomalies = {}
        cursor = self.conn.cursor()

        stock_config = Config.get_stock_config()

        for ticker in stock_config.keys():
            ticker_anomalies = []

            # 1. ê°€ê²© ê´€ê³„ ìœ„ë°˜ ì²´í¬ (high < low, close > high, close < low ë“±)
            cursor.execute("""
                SELECT date, open_price, high_price, low_price, close_price
                FROM prices
                WHERE ticker = ?
                AND (
                    (high_price IS NOT NULL AND low_price IS NOT NULL AND high_price < low_price)
                    OR (high_price IS NOT NULL AND close_price IS NOT NULL AND close_price > high_price)
                    OR (low_price IS NOT NULL AND close_price IS NOT NULL AND close_price < low_price)
                    OR (high_price IS NOT NULL AND open_price IS NOT NULL AND open_price > high_price)
                    OR (low_price IS NOT NULL AND open_price IS NOT NULL AND open_price < low_price)
                )
            """, (ticker,))

            for row in cursor.fetchall():
                ticker_anomalies.append({
                    'date': row['date'],
                    'type': 'price_relationship_violation',
                    'open': row['open_price'],
                    'high': row['high_price'],
                    'low': row['low_price'],
                    'close': row['close_price']
                })

            # 2. ê¸‰ê²©í•œ ê°€ê²© ë³€ë™ ì²´í¬ (ì „ì¼ ëŒ€ë¹„ Â±50% ì´ìƒ)
            cursor.execute("""
                SELECT date, close_price, daily_change_pct
                FROM prices
                WHERE ticker = ?
                AND ABS(daily_change_pct) > 50.0
                ORDER BY date
            """, (ticker,))

            for row in cursor.fetchall():
                ticker_anomalies.append({
                    'date': row['date'],
                    'type': 'extreme_price_change',
                    'close_price': row['close_price'],
                    'change_pct': row['daily_change_pct']
                })

            if ticker_anomalies:
                anomalies[ticker] = ticker_anomalies
                self.issues['anomalies'].append({
                    'ticker': ticker,
                    'count': len(ticker_anomalies),
                    'examples': ticker_anomalies[:3]
                })

        logger.info(f"ê°€ê²© ì´ìƒì¹˜: {sum(len(v) for v in anomalies.values())}ê±´")
        return anomalies

    def get_collection_status(self) -> Dict[str, Dict]:
        """
        ì¢…ëª©ë³„ ìˆ˜ì§‘ í˜„í™©

        Returns:
            ì¢…ëª©ë³„ í†µê³„ ì •ë³´
        """
        logger.info("ì¢…ëª©ë³„ ìˆ˜ì§‘ í˜„í™© ì¡°íšŒ...")

        status = {}
        cursor = self.conn.cursor()

        stock_config = Config.get_stock_config()

        for ticker, info in stock_config.items():
            # ê°€ê²© ë°ì´í„° í†µê³„
            cursor.execute("""
                SELECT
                    COUNT(*) as count,
                    MIN(date) as first_date,
                    MAX(date) as last_date
                FROM prices
                WHERE ticker = ?
            """, (ticker,))

            price_row = cursor.fetchone()

            # ë§¤ë§¤ ë™í–¥ ë°ì´í„° í†µê³„
            cursor.execute("""
                SELECT COUNT(*) as count
                FROM trading_flow
                WHERE ticker = ?
            """, (ticker,))

            trading_row = cursor.fetchone()

            # ë‰´ìŠ¤ ë°ì´í„° í†µê³„
            cursor.execute("""
                SELECT COUNT(*) as count
                FROM news
                WHERE ticker = ?
            """, (ticker,))

            news_row = cursor.fetchone()

            status[ticker] = {
                'name': info['name'],
                'type': info['type'],
                'prices': {
                    'count': price_row['count'],
                    'first_date': price_row['first_date'],
                    'last_date': price_row['last_date']
                },
                'trading_flow': {
                    'count': trading_row['count']
                },
                'news': {
                    'count': news_row['count']
                }
            }

        return status

    def calculate_completeness_score(self, status: Dict) -> Dict[str, float]:
        """
        ë°ì´í„° ì™„ì „ì„± ì ìˆ˜ ê³„ì‚° (0-100)

        Args:
            status: ì¢…ëª©ë³„ ìˆ˜ì§‘ í˜„í™©

        Returns:
            ì¢…ëª©ë³„ ì™„ì „ì„± ì ìˆ˜
        """
        logger.info("ë°ì´í„° ì™„ì „ì„± ì ìˆ˜ ê³„ì‚°...")

        scores = {}

        for ticker, data in status.items():
            score = 0.0

            # ê°€ê²© ë°ì´í„° (50ì )
            if data['prices']['count'] > 0:
                score += 50.0

            # ë§¤ë§¤ ë™í–¥ ë°ì´í„° (25ì )
            if data['trading_flow']['count'] > 0:
                score += 25.0

            # ë‰´ìŠ¤ ë°ì´í„° (25ì )
            if data['news']['count'] > 0:
                score += 25.0

            scores[ticker] = score

        return scores

    def generate_report(self) -> str:
        """
        ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„±

        Returns:
            ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¦¬í¬íŠ¸
        """
        logger.info("ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")

        # ëª¨ë“  ê²€ì¦ ì‹¤í–‰
        duplicates = self.check_duplicate_prices()
        null_stats = self.check_null_values()
        missing_dates = self.check_date_continuity()
        anomalies = self.check_price_anomalies()
        status = self.get_collection_status()
        scores = self.calculate_completeness_score(status)

        # ë¦¬í¬íŠ¸ ìƒì„±
        report = []
        report.append("# ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë¦¬í¬íŠ¸")
        report.append(f"\n**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        # 1. ì¢…í•© ìš”ì•½
        report.append("## ğŸ“Š ì¢…í•© ìš”ì•½\n")
        total_issues = sum(len(v) for v in self.issues.values())
        report.append(f"- **ì´ ì´ìŠˆ ê±´ìˆ˜**: {total_issues}ê±´")
        report.append(f"  - ì¤‘ë³µ ë°ì´í„°: {len(self.issues['duplicates'])}ê±´")
        report.append(f"  - NULL ê°’: {len(self.issues['null_values'])}ê±´")
        report.append(f"  - ë‚ ì§œ ëˆ„ë½: {len(self.issues['missing_dates'])}ê°œ ì¢…ëª©")
        report.append(f"  - ê°€ê²© ì´ìƒì¹˜: {sum(len(v) for v in anomalies.values())}ê±´")

        # 2. ì¢…ëª©ë³„ ìˆ˜ì§‘ í˜„í™©
        report.append("\n## ğŸ“ˆ ì¢…ëª©ë³„ ìˆ˜ì§‘ í˜„í™©\n")
        report.append("| ì¢…ëª©ì½”ë“œ | ì¢…ëª©ëª… | íƒ€ì… | ê°€ê²© ë°ì´í„° | ë§¤ë§¤ ë™í–¥ | ë‰´ìŠ¤ | ì™„ì „ì„± ì ìˆ˜ |")
        report.append("|---------|-------|------|-----------|----------|------|------------|")

        for ticker, data in status.items():
            report.append(
                f"| {ticker} | {data['name']} | {data['type']} | "
                f"{data['prices']['count']}ê±´ | "
                f"{data['trading_flow']['count']}ê±´ | "
                f"{data['news']['count']}ê±´ | "
                f"{scores[ticker]:.0f}ì  |"
            )

        # 3. ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„
        report.append("\n## ğŸ“… ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„\n")
        report.append("| ì¢…ëª©ì½”ë“œ | ìµœì´ˆ ìˆ˜ì§‘ì¼ | ìµœê·¼ ìˆ˜ì§‘ì¼ | ìˆ˜ì§‘ ì¼ìˆ˜ |")
        report.append("|---------|-----------|-----------|---------|")

        for ticker, data in status.items():
            if data['prices']['count'] > 0:
                report.append(
                    f"| {ticker} | {data['prices']['first_date']} | "
                    f"{data['prices']['last_date']} | {data['prices']['count']}ì¼ |"
                )

        # 4. NULL ê°’ í†µê³„
        if null_stats:
            report.append("\n## âš ï¸ NULL ê°’ í†µê³„\n")
            for table, stats in null_stats.items():
                total = stats.get('total_records', 0)
                if total > 0:
                    report.append(f"\n### {table} í…Œì´ë¸”\n")
                    report.append("| ì»¬ëŸ¼ | NULL ê±´ìˆ˜ | ë¹„ìœ¨ |")
                    report.append("|------|----------|------|")

                    for col, count in stats.items():
                        if col != 'total_records' and count > 0:
                            pct = round(count / total * 100, 2)
                            report.append(f"| {col} | {count}ê±´ | {pct}% |")

        # 5. ë‚ ì§œ ëˆ„ë½ ì´ìŠˆ
        if self.issues['missing_dates']:
            report.append("\n## ğŸ“† ë‚ ì§œ ëˆ„ë½ ì´ìŠˆ\n")
            for issue in self.issues['missing_dates']:
                report.append(f"\n### {issue['ticker']} ({issue['count']}ì¼ ëˆ„ë½)")
                if issue['dates']:
                    report.append(f"- ì˜ˆì‹œ: {', '.join(issue['dates'][:5])}")
                    if issue['count'] > 5:
                        report.append(f"  - (ì™¸ {issue['count'] - 5}ì¼ ë” ëˆ„ë½)")

        # 6. ê°€ê²© ì´ìƒì¹˜
        if self.issues['anomalies']:
            report.append("\n## ğŸš¨ ê°€ê²© ì´ìƒì¹˜\n")
            for issue in self.issues['anomalies']:
                report.append(f"\n### {issue['ticker']} ({issue['count']}ê±´)")
                for example in issue['examples']:
                    report.append(f"- {example['date']}: {example['type']}")

        # 7. ê¶Œì¥ ì‚¬í•­
        report.append("\n## ğŸ’¡ ê¶Œì¥ ì‚¬í•­\n")
        if total_issues == 0:
            report.append("âœ… ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            if self.issues['duplicates']:
                report.append("- ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ í•„ìš”")
            if self.issues['missing_dates']:
                report.append("- ëˆ„ë½ëœ ë‚ ì§œì˜ ë°ì´í„° ì¬ìˆ˜ì§‘ ê¶Œì¥")
            if self.issues['anomalies']:
                report.append("- ê°€ê²© ì´ìƒì¹˜ í™•ì¸ ë° ë°ì´í„° ì¬ê²€ì¦ í•„ìš”")

        return "\n".join(report)

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.conn.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 80)
    print("ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘")
    print("=" * 80)

    validator = DataQualityValidator()

    try:
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = validator.generate_report()

        # ì½˜ì†” ì¶œë ¥
        print("\n" + report)

        # íŒŒì¼ ì €ì¥
        report_path = Path(__file__).parent.parent / "data" / "data_quality_report.md"
        report_path.write_text(report, encoding='utf-8')

        print(f"\në¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        print("=" * 80)

    finally:
        validator.close()


if __name__ == "__main__":
    main()
